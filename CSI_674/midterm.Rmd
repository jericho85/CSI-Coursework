---
title: "Bayesian Stats Midterm<br>Jericho McLeod"
output: html_notebook
---

<b>Problem 1:</b> A security screening system photographs people entering a facility, matches them to a database of terrorist suspects, and alerts security to stop an individual for further scrutiny if a match is found. The system has a miss probability of 12% and a false alarm probability of 4%, where a miss is defined as failing to issue an alert for a person in the database, and a false alarm is defined as issuing an alert for a person who is not in the database. Assume that true positives and true negatives cost nothing, and the cost of a miss is 150 times the cost of a false alarm. Let p be the prior probability that a person is in the database. Plot the expected loss of three policies: (1) stop everyone for questioning; (2) stop no one for questioning; and (3) stop someone for questioning if an alert is issued. For what range of p is each policy optimal? Comment on your answer.

<table style="width:30%">
  <tr align="right">
    <th>Condition</th>
    <th>flagged</th>
    <th>not flagged</th>
  </tr>
  <tr align="right">
    <td>terrorist</td>
    <td>0.88</td>
    <td>0.12</td>
  </tr>
  <tr align="right">
    <td>citizen</td>
    <td>0.04</td>
    <td>0.96</td>
  </tr>
</table>

<br>
<br>

<table style="width:30%">
  <tr align="right">
    <th>Condition</th>
    <th>flagged</th>
    <th>not flagged</th>
  </tr>
  <tr align="right">
    <td>terrorist</td>
    <td>0</td>
    <td>150</td>
  </tr>
  <tr align="right">
    <td>citizen</td>
    <td>1</td>
    <td>0</td>
  </tr>
</table>
<br><br>
cost of terrorist_not_flagged = 150<br>
cost of citizen_flagged       = 1<br>
<br>
P = probability of terrorist<br>

```{r}
# X values for plot
p_vals <- seq(0,100,1)/100      # represents terrorists

# Y values for various strategies
flag_none  <- 150*p_vals        # no cost to citizens
flag_all <- 1*(1-p_vals)        # no costs attributed to terrorists
follow_test <- ((1-p_vals)*1*0.04)+(p_vals*150*0.12)

plot(seq(0,1,0.01),flag_none,
     type="l",
     col="blue",
     main="Utility of Screening",
     xlab="Probability Terrorist",
     ylab="Expected Cost",
     xlim=c(0,.08),
     ylim=c(0,1))
lines(seq(0,1,0.01),flag_all,col='green')
lines(seq(0,1,0.01),follow_test,col="red")
legend(0.06,0.30,c("Flag none","Flag all","FollowTest"),col=c("blue","green","red"),lty=c(1,1,1))

```

'Flag none' is only an optimum strategy when P=0. <br>
For 0 < P < ~0.05, following the test the is the best strategy. <br>
For P > ~0.05, talking to everyone is the best strategy. <br>

These are notably small probabilities, and this relates directly to the fact that the cost of a miss is 150 times that of incorrectly flagging someone who is not in the DB of potential terrorists. Additionally, there are no costs for correct classifications, simplifying the plots somewhat. <br><br>

<b>Problem 2:</b> Historically, one in every 50 fourth-graders at an elementary school fails to reach minimum threshold on a state-mandated reading exam. The school is planning a study to evaluate a new reading curriculum. A school administrator assesses a 55% chance that the new curriculum would reduce the failure rate for the exam. That is, there is a 55% chance that if the new curriculum were implemented, fewer than 1 in 50 students would fail the exam. Suppose the administrator also assesses a 45% chance that the failure rate would be cut in half and a 30% chance that the fail rate is improved by a factor of 10. That is, there is a 45% chance that fewer than 1 in 100 students would fail the exam, and a 30% chance that fewer than 2 in 1000 students would fail the exam under the new curriculum. The administrator also assesses a 35% chance that the failure rate would more than double, or at least 4% of the students would fail the exam. If you were to use a Beta distribution to fit these judgments, what parameters would you use? Do you think it provides a good fit? Justify your answer.

Current Failure Rate: 2%
New rates:
    55% Chance < 2%
    45% Chance < 1%
    30% Chance < 0.2%
    35% Chance > 4%

```{r}
require(rriskDistributions)

#Inputting Data
fail_count <- c( 0.002, 0.01, 0.02, 0.04)
chance <- c( 0.30, 0.45, 0.55, 0.65)

#Using a fitting function to determnie the shape and scale
params <- get.beta.par(p=chance,q=fail_count)

#The following is not strictly  necessary; I just wanted
#to be sure I understood the auto-generated chart.
shape <- params[1]
scale <- params[2]
betas <- qbeta(probas,shape1=shape,shape2=scale)

#Plot the expert opinion with the fitted beta distribution
plot(fail_count,chance,xlim=c(0,1),ylab='Probability',xlab='Quantiles',ylim=c(0,1))
lines(betas,probas,type='l')

```
The parameters I would use are shape = 0.27 and scale = 4.17. This is a good fit  in terms of variance from the data. However, it is necessary to change the 35% chance of the failure rate being > 4% to match  the rest of the inputs. It makes more sense to say  there is a 65% chance that < 4% will fail. This then gives us a good beta quantile distribution in terms of fitting the data points. <br><br>

<h1>incomplete</h1><b>Problem 3:</b> A shape recognition system classifies objects as round, rectangular, or irregular. It correctly classifies round objects 80% of the time, rectangular objects 85% of the time, and irregular objects 70% of the time. Incorrectly classified objects are equally likely to be classified as either of the two incorrect object types. Assume in a given environment that 15% of the objects are round, 25% of the objects are rectangular, and 60% of the objects are irregularly shaped. Find the joint distribution of object shapes and classification results. If the system reports that an object is rectangular, what is the posterior probability that the object has each of the three shapes given the system report?

P(correct | round) = 0.80
P(correct | rect)  = 0.85
P(correct | irreg) = 0.70

P(round) = 0.15
P(rect)  = 0.25
p(irreg) = 0.60

Defining this problem as a vector [round, rectangle, irregular], the form of the joint distribution is a matrix comparing actual shape to classification results, also called a confusion matrix. 

<table style="width:50%">
  <tr align="right">
    <th>Confusion Matrix</th>
    <th>Class: Round</th>
    <th>Class: Rect</th>
    <th>Class: Irreg</th>
  </tr>
  <tr align="right">
    <td><b>Actual: Round</b></td>
    <td>0.80</td>
    <td>0.10</td>
    <td>0.10</td>
  </tr>
  <tr align="right">
    <td><b>Actual: Rect</b></td>
    <td>0.075</td>
    <td>0.85</td>
    <td>0.075</td>
  </tr>
  <tr align="right">
    <td><b>Actual: Irreg</b></td>
    <td>0.15</td>
    <td>0.15</td>
    <td>0.70</td>
  </tr>
</table>

```{r}
prob_round <- 0.1/(0.1+0.85+0.15)
prob_rect <- 0.85/(0.1+0.85+0.15)
prob_irreg <- 0.15/(0.1+0.85+0.15)

print(prob_round)
print(prob_rect)
print(prob_irreg)
```


<b>Problem 4:</b> A drug for treating depression is undergoing clinical trials. A total of 120 patients were enrolled in a randomized, double-blind, placebo-controlled study. Half of the patients were randomly selected to receive the drug; the remaining patients were given a placebo. Questionnaires were administered at the start of the study and 30 days after treatment began. One of the questions on the post-study questionnaire asked whether patients experienced improvement in their mood since the start of the study. The table below shows responses to this question.

<table style="width:40%">
  <tr>
    <th></th>
    <th  align="right">No Improvement</th>
    <th  align="right">Improvement</th>
    <th  align="right">Total</th>
  </tr>
  <tr align="right">
    <td>Treatment (Y1)</td>
    <td>18</td>
    <td>42</td>
    <td>60</td>
  </tr>
  <tr align="right">
    <td>Placebo (Y2)</td>
    <td>26</td>
    <td>34</td>
    <td>60</td>
  </tr>
  <tr align="right">
    <td>Total</td>
    <td>44</td>
    <td>76</td>
    <td>120</td>
  </tr>
</table>

Let Y1 and Y2 be the number of patients in the treatment and placebo groups who experienced improvement. Assume Y1 and Y2 are independent random variables with Binomial(60, $\theta_i$) distributions, for i=1,2. Assume $\theta_1$ and $\theta_2$ are independent with a Beta distribution with shape parameters 1⁄2 and 1⁄2 (this is the Jeffreys prior distribution). Find the joint posterior distribution for $\theta_1$ and $\theta_2$. Name the distribution type and its hyperparameters. Plot the posterior density functions for $\theta_1$ and $\theta_2$ on the same axes. Comment on your results.

Treatments: 60
Treatment Successes: 42
Placebos: 60
Placebo Successes: 34

```{r}


#Entering Jeffreys  prior
treatment_prior_shape  <- 1/2
treatment_prior_scale  <- 1/2
placebo_prior_shape <- 1/2
placebo_prior_scale <- 1/2

#Find posteriors  given data
treatment_posterior_shape <- treatment_prior_shape + 42
treatment_posterior_scale <- treatment_prior_scale + 18
placebo_posterior_shape <- placebo_prior_shape + 34
placebo_posterior_scale <- placebo_prior_scale + 26 

#Plot beta distributions to see the space
x <- seq(0,1,length=100)
lambda1 <- dbeta(x,shape1=treatment_posterior_shape,shape2=treatment_posterior_scale)
lambda2 <- dbeta(x,shape1=placebo_posterior_shape,shape2=placebo_posterior_scale)
c_int1 <- qbeta(c(.025,.975),shape1=treatment_posterior_shape,shape2=treatment_posterior_scale)
c_int2 <- qbeta(c(.025,.975),shape1=placebo_posterior_shape,shape2=placebo_posterior_scale)
plot(x,lambda1,type='l',col='blue',ylim=c(0,7),ylab='Density',xlab='Probability')
lines(x,lambda2,col='red')
segments(x0 = c_int1[1], y0 = -.10, x1 = c_int1[2], y1 = -.10,col='blue')
segments(x0 = c_int2[1], y0 = -.20, x1 = c_int2[2], y1 = -.20,col='red')
points(c_int1[1],-.1,col='blue',pch='x')
points(c_int1[2],-.1,col='blue',pch='x')
points(c_int2[1],-.2,col='red',pch='x')
points(c_int2[2],-.2,col='red',pch='x')
legend(0,7,c("Treatment","Placebo"),col=c("blue","red"),lty=c(1,1))


#Simulate these distributions to find the joint posterior that treatment is better than placebo
numSim <- 10000
lambda1 <- rbeta(sample_size,shape1=treatment_posterior_shape,shape2=treatment_posterior_scale)
lambda2 <- rbeta(sample_size,shape1=placebo_posterior_shape,shape2=placebo_posterior_scale)
diff <- lambda1-lambda2
print(mean(diff))
h <- diff>0

meanMC <- mean(h)
sdevMC <- sqrt(var(h)/numSim) 
print(meanMC)
print(sdevMC)

#plot the joint posterior distribution, which is is normal
x <- seq(0.92,0.95,length=100)
norm_dist <- dnorm(x,meanMC,sdevMC)
plot(x,norm_dist,type='l',ylab='Density',xlab='Probability')
```



<b>Problem 5:</b> Generate 5000 random pairs ($\theta_{1i},\theta_{2i}$), i=1, ..., 5000 from the joint posterior distribution for ($\theta_1$, $\theta_2$). Use this random sample to estimate the posterior probability that the rate of improvement is higher for treatment than for placebo. Does your analysis support the hypothesis that the drug alleviates symptoms of depression? Explain clearly your process for generating the sample. Discuss your analysis and results.

```{r}
library(MASS)

#Monte Carlo sample  size
sample_size <- 5000

#calculate the lambda values in monte carlo  and take the difference
lambda1 <- rbeta(sample_size,shape1=treatment_posterior_shape,shape2=treatment_posterior_scale)
lambda2 <- rbeta(sample_size,shape1=placebo_posterior_shape,shape2=placebo_posterior_scale)

Difference  <-  lambda1-lambda2
probTreatBetter <- sum(Difference>0)/length(Difference) 

print(probTreatBetter)

#Iterate over Monte Carlo simulation to get sample distribution of differences
iters  <- seq(0,1,length=10000)
mc_result <- c()
for (i in iters){
  lambda1 <- rbeta(sample_size,shape1=treatment_posterior_shape,shape2=treatment_posterior_scale)
  lambda2 <- rbeta(sample_size,shape1=placebo_posterior_shape,shape2=placebo_posterior_scale)
  Difference  <-  lambda1-lambda2
  probTreatBetter <- sum(Difference>0)/length(Difference)
  mc_result  <- c(mc_result,probTreatBetter)
}

#plotting the histogram  of results
hist_data  <- hist(mc_result,prob=TRUE)
lines(density(mc_result))

#Fitting normal distribution
#This can also be done analytically  by just taking
#the mean and standard distribution
fit_params  <-fitdistr(mc_result,'normal')  
print(fit_params)

#  Values I got running this:
#       mean            sd     
#  9.354622e-01   3.492441e-03

range <- seq(.91,.96,length=100)
normal <-dnorm(range,mean=9.354622e-01,sd=3.492441e-03  )
plot(range,normal,type="l",col='blue',xlab='Probability Treatment > Placebo',ylab='Density')
lines(hist_data$mids,hist_data$density,col='red')
legend(0.91,49,c("Normal Dist","Counts Density"),col=c("blue","red"),lty=c(1,1))
```


<b>Problem 6:</b> Suppose 25 new patients are given the drug. Using the posterior distribution from problem 4 as the prior distribution for the probability of reporting improvement, find the predictive distribution for the number of patients who will report improvement 30 days after receiving the drug. State the distribution type and parameters. Find the posterior probability that 20 or more patients will report improvement in 30 days.

```{r}
treatment_posterior_shape
treatment_posterior_scale

library("rmutil")

p = treatment_posterior_shape  / (treatment_posterior_shape+treatment_posterior_scale)
m = treatment_posterior_shape+treatment_posterior_scale
n = 25

# Predictive Dist
pred_dist <-  dbetabinom(seq(0,25,1),n,p,m)
plot(seq(0,25,1),pred_dist,type="l",ylim=c(0,.15),col='black',     xlab="Trials",
     ylab="Probability  ",)


#Visually checking to make sure this makes sense
probability_20 <- pbetabinom(seq(1,25,length=25),n,p,m)
plot(probability_20,xlab='Patients Improved',ylab='Probability')

#getting the actual answer required
probability_20 <- pbetabinom(20,n,p,m)
print(probability_20)
```


<b>Problem 7:</b> A researcher is performing a study of plant growth. To model the number of plants of a given species that will be found on a $10 m^2$ plot of land, she uses a Poisson distribution with unknown rate parameter $\lambda$ that depends on the species and the soil conditions. Based on her knowledge of plants and soil conditions, she assesses a conjugate Gamma prior distribution with shape 2 and scale 6 for the mean number of plants growing on a $10 m^2$ plot of land of a given type. She plans to count the number of plants growing on five plots of this given type. What is her predictive distribution for the total number of plants she will find growing on the five plots? Find the probability that she will count fewer than a total of 75 plants growing on the five plots.


```{r}
g_shape_prior <- 2
g_scale_prior <- 6

plants_density  <- dgamma(seq(0,100,length=101),shape=g_shape_prior,scale=g_scale_prior)
plot(seq(0,100,length=101),plants_density,type='l')

PMF_5_Fields <- dnbinom(seq(0,200,length=201), size=g_shape_prior, prob=1/(1+5*g_scale_prior))
Plants <- seq(0,200,length=201)
plot(Plants,PMF_5_Fields,type='l')

prob75 <- pnbinom(75, size=g_shape_prior, prob=1/(1+5*g_scale_prior))
prob75

count_probas <- pnbinom(seq(0,200,length=201), size=g_shape_prior, prob=1/(1+5*g_scale_prior))
plot(count_probas,pch=20)
```


<h1>Not started</h1><b>Problem 8:</b> The researcher goes out into the field and counts the plants she finds on the five plots. She counts a total of 72 plants. Find her posterior distribution for the Poisson parameter $\lambda$. Name the type of distribution and hyperparameters. Find a 95% credible interval for $\lambda$.

```{r}

# The  posterior is a gamma dist
g_shape_posterior <- 2 +  72
g_scale_posterior <- 1/  (1/6 + 5)
print(g_shape_posterior)
print(g_scale_posterior)
plant_post <- dgamma(seq(0,100,length=101),shape=g_shape_posterior,scale=g_scale_posterior)
plot(seq(0,100,length=101),plants_density,type='l')

cred_int <- qgamma(c(0.05,0.95), shape=g_shape_posterior, scale =g_scale_posterior)
print(cred_int)

```

<b>Problem 9:</b> Management at a call center is investigating the call load in order to find an efficient staffing policy. Assume that time intervals between calls are exponentially distributed. Assume the mean time between calls $\Theta$ is constant during the mid-morning period. Assume an inverse Gamma prior distribution with shape $\alpha$ =4 and scale $\beta$ = 0.0015 for $\Theta$. The following sequence of call times was collected during mid-morning, measured in seconds after the start of data collection: 168, 314, 560, 754, 1215, 1493, 1757, 1820, 1871, 1982, 2134, 2430, 3187, 3388, 3485. Find the posterior distribution for $\Theta$. Find the prior and posterior mean and standard deviation for $\Theta$. Discuss. (Note: Because of the memoryless property of the exponential distribution, you can treat the time until the first call as having an exponential distribution.)

```{r}

#visualizing the prior
require(invgamma)
alpha = 4
beta =  0.0014
v <- seq(0,1000,length=1000)
invgdist <- dinvgamma(v,shape=alpha,scale=beta)
plot(invgdist,type='l')

#updating data to be in the form I prefer (time since last)
obs <- c(168, 314, 560, 754, 1215, 1493, 1757, 1820, 1871, 1982, 2134, 2430, 3187, 3388, 3485)
obs_diff <- diff(obs)
obs <- c(168,obs_diff) # adding back the first time period
obs

theta  <- mean(obs)
theta

# Formulas to use:
# alpha* = alpha X n
# beta* =  (beta^-1 + sum(X_i))^-1
alpha_posterior <- alpha + length(obs)
beta_posterior <- (1/beta + sum(obs))^-1
alpha_posterior
beta_posterior

invgdist_post <- dinvgamma(v,shape=alpha_posterior,scale=beta_posterior)
plot(invgdist_post,type='l',col='blue')
lines(invgdist,col='green')
legend(700,.008,c("Prior","Posterior"),col=c("green","blue"),lty=c(1,1))

prior_mean <- 1 / (beta * (alpha-1))
prior_sd <- (1 / (beta^2 * (alpha-1)^2  * (alpha-2) ))^0.5
posterior_mean <- 1 / (beta_posterior * (alpha_posterior-1))
posterior_sd <- (1 / (beta_posterior^2 * (alpha_posterior-1)^2  * (alpha_posterior-2) ))^0.5

print(prior_mean)
print(prior_sd)
print(posterior_mean)
print(posterior_sd)


(prior_mean-posterior_mean) / prior_mean
```


<h1>incomplete</h1><b>Problem 10:</b> Do you think the model of independent and identically distributed exponential observations is a good model for the data of Problem 9? Explain your reasoning.

The model is a good  model for the data, but no for the problem being solved. It would make more sense to solve a staffing  problem with a discretized distribution. In this case, a poisson and gamma conjugate distribution feels like a more appropriate selection that makes solving the staffing problem simpler for stakeholders. 


```{r}

```






















