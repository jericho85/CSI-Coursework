{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jericho McLeod<br>CSI-873<br>Homework 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a weighted k-nearest neighbor algorithm for the available hand-written training data. Test the algorithm on the testing data. Provide accuracy results for the following 15 cases:\n",
    "\n",
    "1) k = 1, 2, ..., 7; all the weights are equal to 1<br>\n",
    "2) k = 1, 2, ..., 7; all the weights are calculated according to the formula: $$ w_i = \\frac{1}{d(x_q,x_i)^2+\\varepsilon},\\varepsilon = 1 $$\n",
    "3) k = all training points; all the weights are calculated according to the formula: $$ w_i = \\frac{1}{d(x_q,x_i)^2+\\varepsilon},\\varepsilon = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four cells import the necessary libraries for importing, copying, and plotting, functions to import the data, statements to call the import functions and create data structures, and some verification that importing is complete.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(file):\n",
    "    data = []\n",
    "    with open(file, 'r') as csvfile:\n",
    "        csv_r = csv.reader(csvfile,delimiter=' ')\n",
    "        for row in csv_r:\n",
    "            row_nums = []\n",
    "            for i in range(len(row)):\n",
    "                try:\n",
    "                    val = float(row[i])\n",
    "                    if i > 0:\n",
    "                        val = round(val/255,4)\n",
    "                        # The above line scales the data imported\n",
    "                    row_nums.append(val)\n",
    "                except:\n",
    "                    print('ERROR on import: non-numerical data:',row[i])\n",
    "                    break                    \n",
    "            data.append(row_nums)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import_loop(string,denom):\n",
    "    files = []\n",
    "    data_dict = {}\n",
    "    for i in range(10):\n",
    "        file_name = string+str(i)+'.txt'\n",
    "        files.append(file_name)\n",
    "        data_dict[i]=[]\n",
    "    for i in files:\n",
    "        data = data_import(i)\n",
    "        for j in range(len(data)):\n",
    "            if j%denom==0: # SUBSET data \n",
    "                data_dict[data[j][0]].append(data[j][1:])\n",
    "    return(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denom = 5\n",
    "data_dict = data_import_loop('train',denom)\n",
    "denom = 4\n",
    "test_dict = data_import_loop('test',denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Training Obs: 1185    Testing Obs: 245\n",
      "1    Training Obs: 1349    Testing Obs: 284\n",
      "2    Training Obs: 1192    Testing Obs: 258\n",
      "3    Training Obs: 1227    Testing Obs: 253\n",
      "4    Training Obs: 1169    Testing Obs: 246\n",
      "5    Training Obs: 1085    Testing Obs: 223\n",
      "6    Training Obs: 1184    Testing Obs: 240\n",
      "7    Training Obs: 1253    Testing Obs: 257\n",
      "8    Training Obs: 1171    Testing Obs: 244\n",
      "9    Training Obs: 1190    Testing Obs: 253\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i,'   Training Obs:',len(data_dict[i]),'   Testing Obs:',len(test_dict[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells subset data to 250 of each digit in the training data and 50 of each digit in the testing data, the verify the subset is completed.  \n",
    "\n",
    "This is not a randomized function, merely trimming the first X observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = {}\n",
    "test_subset = {}\n",
    "for i in range(10):\n",
    "    for j in range(250):\n",
    "        if i in data_subset:\n",
    "            data_subset[i].append(data_dict[i][j])\n",
    "        else:\n",
    "            data_subset[i] = [data_dict[i][j]]\n",
    "    for j in range(50):\n",
    "        if i in test_subset:\n",
    "            test_subset[i].append(test_dict[i][j])\n",
    "        else:\n",
    "            test_subset[i] = [test_dict[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 250 50\n",
      "1 250 50\n",
      "2 250 50\n",
      "3 250 50\n",
      "4 250 50\n",
      "5 250 50\n",
      "6 250 50\n",
      "7 250 50\n",
      "8 250 50\n",
      "9 250 50\n"
     ]
    }
   ],
   "source": [
    "for k,v in data_subset.items():\n",
    "    print(k,len(v),len(test_subset[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell merely converts the data to a list of lists rather than a dictionary for simplified loops in following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_matrix = []\n",
    "d_results = []\n",
    "for k,v in data_subset.items():\n",
    "    for i in v:\n",
    "        d_matrix.append(i)\n",
    "        d_results.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function below calculates the euclidean distance of two vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(v1,v2):\n",
    "    if len(v1)==len(v2):\n",
    "        sq = 0\n",
    "        for i in range(len(v1)):\n",
    "            sq += (v1[i]-v2[i])**2\n",
    "        dist = sq**0.5\n",
    "        return(dist)\n",
    "    else:\n",
    "        print('Error: vectors not the same length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses K-Nearest Neighbors to classify an instance. It first creates a set of temporary data structures, then finds the euclidean distance to each point in the training to do the target instance and, if needed, the weight of that distance, then finds the K nearest neighbors, and finally uses these to classify the new instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_class(data,input_results,k,w,target):\n",
    "    # Setting up temp data structures\n",
    "    results = copy.deepcopy(input_results)\n",
    "    dist_vec,weight_vec,knn,class_dict = [],[],[],{}\n",
    "\n",
    "    # Find Euclidean distance and weights for all points\n",
    "    for i in data:\n",
    "        dist = euclidean(i,target)\n",
    "        dist_vec.append(dist)\n",
    "        if w == True:\n",
    "            weight = 1 / (1 + dist**2)\n",
    "            weight_vec.append(weight)\n",
    "            \n",
    "    # Find the K nearest neighbors\n",
    "    for i in range(k):\n",
    "        min_index = dist_vec.index(min(dist_vec))\n",
    "        d0 = dist_vec.pop(min_index)\n",
    "        r0 = results.pop(min_index)\n",
    "        if w == True:\n",
    "            w0 = weight_vec.pop(min_index)\n",
    "        else: w0 = 1\n",
    "        knn.append([d0,w0,r0])\n",
    "    \n",
    "    # Make classification\n",
    "    for i in knn:\n",
    "        #print(i)\n",
    "        if i[2] not in class_dict:\n",
    "            class_dict[i[2]] = i[1]\n",
    "        else:\n",
    "            class_dict[i[2]] += i[1]\n",
    "    return(max(class_dict, key=class_dict.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will report on the overall accuracy of the model using confidence intervals over the entire model, not by individual digit. Confidence Intervals calculated as:$$ errors_S (h) \\pm z_N \\sqrt{ \\frac{errors_S (h)(1-error_S (h))}{n} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(n,p,z):\n",
    "    conf = z * (((p*(1-p))/n)**0.5)\n",
    "    return(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.898 0.02652829408763405\n",
      "2 0.898 0.02652829408763405\n",
      "3 0.912 0.024831892783273687\n",
      "4 0.904 0.025822060893739673\n",
      "5 0.912 0.024831892783273687\n",
      "6 0.918 0.02404912811725198\n",
      "7 0.902 0.02606077794694548\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for k,v in test_subset.items():\n",
    "        total+=len(v)\n",
    "        for j in v:\n",
    "            knn_out = knn_class(d_matrix,d_results,i,False,j)\n",
    "            #print(i,k,len(j),knn_out)\n",
    "            if knn_out == k:\n",
    "                correct+=1\n",
    "    ratio = correct / total\n",
    "    ci = confidence(total,ratio,1.96)\n",
    "    print(i,ratio,ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.898 0.02652829408763405\n",
      "2 0.898 0.02652829408763405\n",
      "3 0.912 0.024831892783273687\n",
      "4 0.908 0.025334241555649534\n",
      "5 0.914 0.024574992427262306\n",
      "6 0.922 0.02350627599599732\n",
      "7 0.904 0.025822060893739673\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for k,v in test_subset.items():\n",
    "        total+=len(v)\n",
    "        for j in v:\n",
    "            knn_out = knn_class(d_matrix,d_results,i,True,j)\n",
    "            #print(i,k,len(j),knn_out)\n",
    "            if knn_out == k:\n",
    "                correct+=1\n",
    "    ratio = correct / total\n",
    "    ci = confidence(total,ratio,1.96)\n",
    "    print(i,ratio,ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.652 0.04175269269400477\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for k,v in test_subset.items():\n",
    "    total+=len(v)\n",
    "    for j in v:\n",
    "        knn_out = knn_class(d_matrix,d_results,len(d_results),True,j)\n",
    "        #print(i,k,len(j),knn_out)\n",
    "        if knn_out == k:\n",
    "            correct+=1\n",
    "ratio = correct / total\n",
    "ci = confidence(total,ratio,1.96)\n",
    "print(i,ratio,ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent loss of data across multiple runs, I have copied out a set of results and will use them for charts. \n",
    "\n",
    "Similar results can be obtained by re-running this notebook with 250 of each number in the training data, and 50 of each number in the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_results = [0.898,0.898, 0.912, 0.904, 0.912, 0.918, 0.902] \n",
    "x_w_results = [0.898,0.898, 0.912, 0.908, 0.914, 0.922, 0.904 ]\n",
    "x_errors = [0.02652829408763405,0.02652829408763405,\\\n",
    "            0.024831892783273687,0.025822060893739673,\\\n",
    "            0.024831892783273687,0.02404912811725198,\\\n",
    "            0.02606077794694548]\n",
    "x_w_errors = [0.02652829408763405,0.02652829408763405,\\\n",
    "              0.024831892783273687,0.025334241555649534,\\\n",
    "              0.024574992427262306,0.02350627599599732,\\\n",
    "              0.025822060893739673]\n",
    "\n",
    "y1,y2 = [],[]\n",
    "for i in range(1,8):\n",
    "    y1.append(i-0.07)\n",
    "    y2.append(i+0.07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In blue is shown the 95% confidence intervals (y-axis) for KNN from k=1 to k=7 (x-axis), while in green is the 95% confidence intervals (y-axis) for KNN from k=1 to k=7 (x-axis) with inverse square weights. Red shows the confidence interval when k= the number of training instances using inverse square weights. \n",
    "\n",
    "These are initially the same as the nearestt neighbors would all be weighted heavily. As the number of neighbors grows, however, the increased accuracy of the weighted KNN demonstrates that more distant neighbors are less accurate predictors of new instances.  \n",
    "\n",
    "It is worth noting that k = number of instances resulted in a loss of accuracy. This is likely due to the density of the data relative to the total number of classifications. If there were fewer classes with more distinct spaces, weighting the distances would reduce the impact to considering all points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim((.60, 0.95))\n",
    "plt.errorbar(y, x_results, yerr=x_errors,color='b')\n",
    "plt.errorbar(y2, x_w_results, yerr=x_w_errors, color='g')\n",
    "plt.errorbar(8,0.652,yerr=0.04175269269400477,color='r')\n",
    "plt.xticks(np.arange(9), ('','k=1', 'k=2', 'k=3', 'k=4', 'k=5', 'k=6','k=7','k=n'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
